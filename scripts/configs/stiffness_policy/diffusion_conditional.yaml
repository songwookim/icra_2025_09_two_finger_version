# 조건부(비시퀀스) 확산 정책. CLI에서는 --diffusion-* 인자와 매칭됩니다.
# steps: 확산 단계 수. 늘리면 샘플 품질은 좋아지지만 학습/샘플링 비용도 증가합니다.
steps: 75
# hidden_dim: U-Net 내부 폭. 모델 용량↑, VRAM 사용↑.
hidden_dim: 256
# batch_size: 학습 배치. 큼직할수록 안정적이지만 GPU 메모리 요구가 커집니다.
batch_size: 256
# learning_rate: 학습률. 발산하면 줄이고, 너무 느리면 약간 올립니다.
learning_rate: 1.0e-3
# epochs: 전체 에폭 수. 데이터가 많거나 수렴이 느리면 늘립니다.
epochs: 200
# sampler: ddpm 기본, ddim으로 바꾸면 eta에 따라 더 결정적/빠른 샘플링이 가능합니다.
sampler: ddpm
# eta: DDIM 노이즈 계수. 0은 완전 결정적, 0.5~1.0은 무작위성 증가. DDPM에는 영향 없습니다.
eta: 0.0
